---
title: Rethinking relations- Limitations of pre-training in relational rule learning
date: 2023-10-26
---

Relational reasoning, crucial for analogy, language, and mathematics, involves complex rule acquisition whose mechanisms remain largely unknown. Building on existing research, we hypothesized that mastering component rules enhances learning of more complex integrated relational rules. We created an analog of a math task for judging whether one integer is greater than another, where shapes (triangle, square) represent integers (3, 4), colors (green, red) represent sign (+/-), and spatial arrangement (above) depicts the comparison (greater than). We randomly assigned participants (n=200) into four groups, manipulating pre-training to mastery on one sub-rule (e.g., 4>3?, -4>-3?, or -3>4?) prior to training on the full task with all sub-rules. A fourth group did the full task twice. Mastery in pre-training was a significant predictor of overall success in the full task. Interleaved practice of the sub-rules without pre-training appeared most effective, yet low overall mastery after extensive trials suggests significant interference between sub-rules. This research reveals challenges in relational rule learning and suggests hypotheses for the key contributions to those challenges, including memory of prior examples and interference.

<!--more-->
